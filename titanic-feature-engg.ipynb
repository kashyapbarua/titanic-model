{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Titanic Disaster Dataset Feature Engineering\n\nThis notebook is an attempt towards kick-starting my way around the Titanic dataset to improve my model scores based on feature engineering techniques.\nThis is not going to be an extensive EDA notebook for viewers, as there are already tons of notebooks available with great amount of EDA to understand the intricacies of the dataset from all aspects.\n* We will work with missing value imputations\n* We will also try to combine some features with each other to come up with new ones\n* We will try to improve our scores by building up on our feature engineering process","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:39:43.022922Z","iopub.execute_input":"2021-06-27T15:39:43.023309Z","iopub.status.idle":"2021-06-27T15:39:43.030724Z","shell.execute_reply.started":"2021-06-27T15:39:43.023276Z","shell.execute_reply":"2021-06-27T15:39:43.029112Z"}}},{"cell_type":"code","source":"# Import the required packages here\n\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore') #Remove warning messages within the kernel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T16:22:00.517685Z","iopub.execute_input":"2021-07-06T16:22:00.518030Z","iopub.status.idle":"2021-07-06T16:22:00.522534Z","shell.execute_reply.started":"2021-07-06T16:22:00.517998Z","shell.execute_reply":"2021-07-06T16:22:00.521467Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Import the datasets here\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.525754Z","iopub.execute_input":"2021-07-06T16:22:00.526417Z","iopub.status.idle":"2021-07-06T16:22:00.562552Z","shell.execute_reply.started":"2021-07-06T16:22:00.526351Z","shell.execute_reply":"2021-07-06T16:22:00.561637Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.564106Z","iopub.execute_input":"2021-07-06T16:22:00.564518Z","iopub.status.idle":"2021-07-06T16:22:00.571531Z","shell.execute_reply.started":"2021-07-06T16:22:00.564458Z","shell.execute_reply":"2021-07-06T16:22:00.570567Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(891, 12)\n(418, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Append the train and test dataframes for data cleaning. \n# We also add a flag so that at a later stage, we can split the combined dataframe to train and test again\n\ntrain['test_flag'] = 0\ntest['test_flag'] = 1\ndf_combined = pd.concat([train, test], axis=0, copy=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.573378Z","iopub.execute_input":"2021-07-06T16:22:00.573640Z","iopub.status.idle":"2021-07-06T16:22:00.602193Z","shell.execute_reply.started":"2021-07-06T16:22:00.573614Z","shell.execute_reply":"2021-07-06T16:22:00.600673Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### High level EDA\n\nWe take a look at the % of missing values in each of the features available in the train and test dataset.\n\n_Ignore the missing values in the 'Survived' feature, because of the concatenation the missing values are attributed from the test set_","metadata":{}},{"cell_type":"code","source":"# Check the % missing values in all the columns of the train set\nprint(df_combined.isnull().sum()*100/df_combined.shape[0])\n\n# Ignore the missing values for the output class 'Survived' as they are from the test set","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.605327Z","iopub.execute_input":"2021-07-06T16:22:00.605685Z","iopub.status.idle":"2021-07-06T16:22:00.634738Z","shell.execute_reply.started":"2021-07-06T16:22:00.605652Z","shell.execute_reply":"2021-07-06T16:22:00.633702Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"PassengerId     0.000000\nSurvived       31.932773\nPclass          0.000000\nName            0.000000\nSex             0.000000\nAge            20.091673\nSibSp           0.000000\nParch           0.000000\nTicket          0.000000\nFare            0.076394\nCabin          77.463713\nEmbarked        0.152788\ntest_flag       0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Subsetting for the list of columns which has less to no missing values\n\ndf_subset = df_combined[['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Name', 'Embarked', 'test_flag']]","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.636009Z","iopub.execute_input":"2021-07-06T16:22:00.636709Z","iopub.status.idle":"2021-07-06T16:22:00.644087Z","shell.execute_reply.started":"2021-07-06T16:22:00.636664Z","shell.execute_reply":"2021-07-06T16:22:00.643237Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning and missing value imputation for the columns\n\n* One of the most common approach to feature engineering has been using the **Name** feature to create a Title feature using regex\n* Using the **Cabin** feature to create classes from the initial letter of the column. The nan have been tagged as 'U' or 'Unknown' class in the data\n* We'll not use the **Ticket** feature for now, as that feature didn't make quite a lot of sense to me\n","metadata":{}},{"cell_type":"code","source":"# Cleaning and level modifications for the categorical features\n\nfor dataset in df_subset:\n    df_subset['Title'] = df_subset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(df_subset['Title'], df_subset['Sex'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.645140Z","iopub.execute_input":"2021-07-06T16:22:00.645457Z","iopub.status.idle":"2021-07-06T16:22:00.721508Z","shell.execute_reply.started":"2021-07-06T16:22:00.645428Z","shell.execute_reply":"2021-07-06T16:22:00.720451Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Sex       female  male\nTitle                 \nCapt           0     1\nCol            0     4\nCountess       1     0\nDon            0     1\nDona           1     0\nDr             1     7\nJonkheer       0     1\nLady           1     0\nMajor          0     2\nMaster         0    61\nMiss         260     0\nMlle           2     0\nMme            1     0\nMr             0   757\nMrs          197     0\nMs             2     0\nRev            0     8\nSir            0     1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Sex</th>\n      <th>female</th>\n      <th>male</th>\n    </tr>\n    <tr>\n      <th>Title</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Capt</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Col</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Countess</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Don</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Dona</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Dr</th>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>Jonkheer</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Lady</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Major</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Master</th>\n      <td>0</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>Miss</th>\n      <td>260</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mlle</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mme</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mr</th>\n      <td>0</td>\n      <td>757</td>\n    </tr>\n    <tr>\n      <th>Mrs</th>\n      <td>197</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ms</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Rev</th>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>Sir</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for dataset in df_subset:\n    df_subset['Title'] = df_subset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n     'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    df_subset['Title'] = df_subset['Title'].replace('Mlle', 'Miss')\n    df_subset['Title'] = df_subset['Title'].replace('Ms', 'Miss')\n    df_subset['Title'] = df_subset['Title'].replace('Mme', 'Mrs')\n    \ndf_subset[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.722579Z","iopub.execute_input":"2021-07-06T16:22:00.722852Z","iopub.status.idle":"2021-07-06T16:22:00.776252Z","shell.execute_reply.started":"2021-07-06T16:22:00.722824Z","shell.execute_reply":"2021-07-06T16:22:00.775339Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"    Title  Survived\n0  Master  0.575000\n1    Miss  0.702703\n2      Mr  0.156673\n3     Mrs  0.793651\n4    Rare  0.347826","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Master</td>\n      <td>0.575000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miss</td>\n      <td>0.702703</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mr</td>\n      <td>0.156673</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mrs</td>\n      <td>0.793651</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rare</td>\n      <td>0.347826</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_subset['Cabin'] = df_subset['Cabin'].replace(np.nan, 'U')\ndf_subset['Cabin_Class'] = df_subset['Cabin'].astype(str).str[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.778341Z","iopub.execute_input":"2021-07-06T16:22:00.778674Z","iopub.status.idle":"2021-07-06T16:22:00.786507Z","shell.execute_reply.started":"2021-07-06T16:22:00.778643Z","shell.execute_reply":"2021-07-06T16:22:00.785553Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Remove the columns here, for which we have generated our own classes\n\ndf_subset = df_subset.drop(['Ticket', 'Cabin', 'Name'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.788009Z","iopub.execute_input":"2021-07-06T16:22:00.788304Z","iopub.status.idle":"2021-07-06T16:22:00.801972Z","shell.execute_reply.started":"2021-07-06T16:22:00.788276Z","shell.execute_reply":"2021-07-06T16:22:00.800810Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Age\n\n* We find the median of the **Age** feature to impute the missing ages, which is roughly about 20%\n* We use the same **Age** column to create buckets of age groups. For _less than 18 (1)_ and for _greater than or equal to 18 (0)_","metadata":{}},{"cell_type":"code","source":"median_age = df_subset[\"Age\"].median()\ndf_subset[\"Age\"].fillna(median_age, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.803341Z","iopub.execute_input":"2021-07-06T16:22:00.803769Z","iopub.status.idle":"2021-07-06T16:22:00.826663Z","shell.execute_reply.started":"2021-07-06T16:22:00.803718Z","shell.execute_reply":"2021-07-06T16:22:00.825607Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_subset.Age[df_subset.Age < 18] = 1\ndf_subset.Age[df_subset.Age >= 18] = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:00.827984Z","iopub.execute_input":"2021-07-06T16:22:00.828275Z","iopub.status.idle":"2021-07-06T16:22:00.839809Z","shell.execute_reply.started":"2021-07-06T16:22:00.828245Z","shell.execute_reply":"2021-07-06T16:22:00.838625Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_subset['Age'] = df_subset['Age'].astype(int) # Convert the age column to int type to be able to perform operations","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:02.962943Z","iopub.execute_input":"2021-07-06T16:22:02.963304Z","iopub.status.idle":"2021-07-06T16:22:02.971250Z","shell.execute_reply.started":"2021-07-06T16:22:02.963271Z","shell.execute_reply":"2021-07-06T16:22:02.970103Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### SibSp & Parch\n\n* We use the **Siblings** and the **Parents/Children** features combined to generate a feature called **Family Size**\n* Having created a new feature out of the above two, we drop the original features\n* We also use the **Family Size** feature to create buckets. _Family Size = 1 (0), Family Size greater than 1 and less than or equal to 4 (1), Family Size greater than 4 (2)_","metadata":{}},{"cell_type":"code","source":"for dataset in df_subset:\n    df_subset['FamilySize'] = df_subset['SibSp'] + df_subset['Parch'] + 1","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:05.478444Z","iopub.execute_input":"2021-07-06T16:22:05.478791Z","iopub.status.idle":"2021-07-06T16:22:05.492902Z","shell.execute_reply.started":"2021-07-06T16:22:05.478761Z","shell.execute_reply":"2021-07-06T16:22:05.491768Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_subset = df_subset.drop(['SibSp', 'Parch'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:06.499161Z","iopub.execute_input":"2021-07-06T16:22:06.499577Z","iopub.status.idle":"2021-07-06T16:22:06.505576Z","shell.execute_reply.started":"2021-07-06T16:22:06.499540Z","shell.execute_reply":"2021-07-06T16:22:06.504585Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_subset.FamilySize[df_subset.FamilySize == 1] = 0\ndf_subset.FamilySize[(df_subset.FamilySize > 1) & (df_subset.FamilySize <= 4)] = 1\ndf_subset.FamilySize[(df_subset.FamilySize > 4)] = 2","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:06.829824Z","iopub.execute_input":"2021-07-06T16:22:06.830157Z","iopub.status.idle":"2021-07-06T16:22:06.844531Z","shell.execute_reply.started":"2021-07-06T16:22:06.830128Z","shell.execute_reply":"2021-07-06T16:22:06.843411Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Fare\n\n* The **Fare** column has been used to create buckets of Fare class\n* Firstly, the missing values (0.07%) are replaced using Median imputation\n* The buckets are Fare <= 7.91 (0), Fare > 7.91 and Fare <= 14.454 (1), Fare > 14.454 and Fare <= 31 (2), Fare > 31 (3)\n* The Fare buckets have been created based on the percentile of data availabilities","metadata":{}},{"cell_type":"code","source":"df_subset['Fare'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:07.221069Z","iopub.execute_input":"2021-07-06T16:22:07.221469Z","iopub.status.idle":"2021-07-06T16:22:07.232653Z","shell.execute_reply.started":"2021-07-06T16:22:07.221431Z","shell.execute_reply":"2021-07-06T16:22:07.231646Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"count    1308.000000\nmean       33.295479\nstd        51.758668\nmin         0.000000\n25%         7.895800\n50%        14.454200\n75%        31.275000\nmax       512.329200\nName: Fare, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"df_subset['Fare'].fillna(df_subset['Fare'].dropna().median(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:07.431630Z","iopub.execute_input":"2021-07-06T16:22:07.431987Z","iopub.status.idle":"2021-07-06T16:22:07.439486Z","shell.execute_reply.started":"2021-07-06T16:22:07.431957Z","shell.execute_reply":"2021-07-06T16:22:07.438751Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df_subset.Fare[df_subset.Fare <= 7.91] = 0\ndf_subset.Fare[(df_subset.Fare > 7.91) & (df_subset.Fare <= 14.454)] = 1\ndf_subset.Fare[(df_subset.Fare > 14.454) & (df_subset.Fare <= 31)] = 2\ndf_subset.Fare[df_subset.Fare > 31] = 3\ndf_subset['Fare'] = df_subset['Fare'].astype(int) # Convert the fare column to integer type\n\ndf_subset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:07.571446Z","iopub.execute_input":"2021-07-06T16:22:07.571798Z","iopub.status.idle":"2021-07-06T16:22:07.601550Z","shell.execute_reply.started":"2021-07-06T16:22:07.571769Z","shell.execute_reply":"2021-07-06T16:22:07.600486Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass     Sex  Age  Fare Embarked  test_flag Title  \\\n0            1       0.0       3    male    0     0        S          0    Mr   \n1            2       1.0       1  female    0     3        C          0   Mrs   \n2            3       1.0       3  female    0     1        S          0  Miss   \n3            4       1.0       1  female    0     3        S          0   Mrs   \n4            5       0.0       3    male    0     1        S          0    Mr   \n\n  Cabin_Class  FamilySize  \n0           U           1  \n1           C           1  \n2           U           0  \n3           C           1  \n4           U           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>test_flag</th>\n      <th>Title</th>\n      <th>Cabin_Class</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>S</td>\n      <td>0</td>\n      <td>Mr</td>\n      <td>U</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0</td>\n      <td>3</td>\n      <td>C</td>\n      <td>0</td>\n      <td>Mrs</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>0</td>\n      <td>1</td>\n      <td>S</td>\n      <td>0</td>\n      <td>Miss</td>\n      <td>U</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0</td>\n      <td>3</td>\n      <td>S</td>\n      <td>0</td>\n      <td>Mrs</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>1</td>\n      <td>S</td>\n      <td>0</td>\n      <td>Mr</td>\n      <td>U</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Embarked\n\n* We do a simple mode imputation in the Embarked feature which attributes to approximately 0.15% missing","metadata":{}},{"cell_type":"code","source":"mode_embarked = df_subset.Embarked.dropna().mode()[0]\ndf_subset[\"Embarked\"].fillna(mode_embarked, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:07.900526Z","iopub.execute_input":"2021-07-06T16:22:07.900894Z","iopub.status.idle":"2021-07-06T16:22:07.909252Z","shell.execute_reply.started":"2021-07-06T16:22:07.900863Z","shell.execute_reply":"2021-07-06T16:22:07.908087Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# In this step, we use the factorize method to factorize the categorical features that we have created above.\n# This is done for model interpretability\n\ncols_new = ['Embarked', 'Title', 'Sex', 'Cabin_Class']\n\nfor col in cols_new:\n    df_subset[col] = pd.factorize(df_subset[col])[0] + 1\n    \ndf_subset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:08.030707Z","iopub.execute_input":"2021-07-06T16:22:08.031057Z","iopub.status.idle":"2021-07-06T16:22:08.048144Z","shell.execute_reply.started":"2021-07-06T16:22:08.031026Z","shell.execute_reply":"2021-07-06T16:22:08.047060Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  Sex  Age  Fare  Embarked  test_flag  Title  \\\n0            1       0.0       3    1    0     0         1          0      1   \n1            2       1.0       1    2    0     3         2          0      2   \n2            3       1.0       3    2    0     1         1          0      3   \n3            4       1.0       1    2    0     3         1          0      2   \n4            5       0.0       3    1    0     1         1          0      1   \n\n   Cabin_Class  FamilySize  \n0            1           1  \n1            2           1  \n2            1           0  \n3            2           1  \n4            1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>test_flag</th>\n      <th>Title</th>\n      <th>Cabin_Class</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# We split the combined dataset to train and test set again\n\ntrain_set = df_subset[df_subset['test_flag']==0]\ntest_set = df_subset[df_subset['test_flag']==1]\n\ntrain_set['Survived'] = train_set['Survived'].astype(int) # Convert the target feature to integer","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:08.222204Z","iopub.execute_input":"2021-07-06T16:22:08.222574Z","iopub.status.idle":"2021-07-06T16:22:08.231444Z","shell.execute_reply.started":"2021-07-06T16:22:08.222543Z","shell.execute_reply":"2021-07-06T16:22:08.230418Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Check if the train and test split was done properly\n\nprint(train_set.shape)\nprint(test_set.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:08.395903Z","iopub.execute_input":"2021-07-06T16:22:08.396230Z","iopub.status.idle":"2021-07-06T16:22:08.400230Z","shell.execute_reply.started":"2021-07-06T16:22:08.396201Z","shell.execute_reply":"2021-07-06T16:22:08.399526Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(891, 11)\n(418, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove the columns which are not required. Test Flag is not required since we split the data already, and the Survived column is redundant in the test set\n\ntest_set = test_set.drop(['Survived', 'test_flag'], axis = 1)\ntrain_set = train_set.drop(['test_flag'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:08.552497Z","iopub.execute_input":"2021-07-06T16:22:08.552828Z","iopub.status.idle":"2021-07-06T16:22:08.559427Z","shell.execute_reply.started":"2021-07-06T16:22:08.552800Z","shell.execute_reply":"2021-07-06T16:22:08.558523Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_set.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:08.718020Z","iopub.execute_input":"2021-07-06T16:22:08.718372Z","iopub.status.idle":"2021-07-06T16:22:08.731957Z","shell.execute_reply.started":"2021-07-06T16:22:08.718327Z","shell.execute_reply":"2021-07-06T16:22:08.730944Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  Sex  Age  Fare  Embarked  Title  \\\n0            1         0       3    1    0     0         1      1   \n1            2         1       1    2    0     3         2      2   \n2            3         1       3    2    0     1         1      3   \n3            4         1       1    2    0     3         1      2   \n4            5         0       3    1    0     1         1      1   \n\n   Cabin_Class  FamilySize  \n0            1           1  \n1            2           1  \n2            1           0  \n3            2           1  \n4            1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Cabin_Class</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model Implementation Process\n\nWe use the engineered features into the models to check out the scores. Below are the set of models that we use for this Kernel\n1. Logistic Regression\n2. Decision Tree\n3. Random Forest\n4. Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train_set[['Age', 'Sex', 'Embarked', 'Title', 'Pclass', 'FamilySize']]\ny = train_set[['Survived']]","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:13.612123Z","iopub.execute_input":"2021-07-06T16:22:13.612483Z","iopub.status.idle":"2021-07-06T16:22:14.736424Z","shell.execute_reply.started":"2021-07-06T16:22:13.612450Z","shell.execute_reply":"2021-07-06T16:22:14.735515Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:15.283562Z","iopub.execute_input":"2021-07-06T16:22:15.284063Z","iopub.status.idle":"2021-07-06T16:22:15.293103Z","shell.execute_reply.started":"2021-07-06T16:22:15.284030Z","shell.execute_reply":"2021-07-06T16:22:15.291958Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(596, 6) (596, 1)\n(295, 6) (295, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:15.803698Z","iopub.execute_input":"2021-07-06T16:22:15.804198Z","iopub.status.idle":"2021-07-06T16:22:15.813824Z","shell.execute_reply.started":"2021-07-06T16:22:15.804165Z","shell.execute_reply":"2021-07-06T16:22:15.812804Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"     Age  Sex  Embarked  Title  Pclass  FamilySize\n709    0    1         2      4       3           1\n439    0    1         1      1       2           0\n840    0    1         1      1       3           0\n720    1    2         1      3       2           1\n39     1    2         2      3       3           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Pclass</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>709</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>720</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Logistic Regression Model\n\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogistic_model = logreg.fit(X_train, y_train)\npredictions = logistic_model.predict(X_test)\n\nacc_logistic_regressions = round(logistic_model.score(X_train, y_train) * 100, 2)\nacc_logistic_regressions","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:22.465864Z","iopub.execute_input":"2021-07-06T16:22:22.467970Z","iopub.status.idle":"2021-07-06T16:22:22.596776Z","shell.execute_reply.started":"2021-07-06T16:22:22.467925Z","shell.execute_reply":"2021-07-06T16:22:22.595838Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"80.2"},"metadata":{}}]},{"cell_type":"code","source":"# Decision Tree model\nfrom sklearn.tree import DecisionTreeClassifier\n\ndec_tree = DecisionTreeClassifier()\ndecision_tree = dec_tree.fit(X_train, y_train)\nprediction_tree = decision_tree.predict(X_test)\n\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\nacc_decision_tree","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:27.803026Z","iopub.execute_input":"2021-07-06T16:22:27.803601Z","iopub.status.idle":"2021-07-06T16:22:27.933279Z","shell.execute_reply.started":"2021-07-06T16:22:27.803563Z","shell.execute_reply":"2021-07-06T16:22:27.932401Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"85.57"},"metadata":{}}]},{"cell_type":"code","source":"# Random Forest Model\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100)\nrandom_forest = rf.fit(X_train, y_train)\nprediction_forest = random_forest.predict(X_test)\n\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:29.385191Z","iopub.execute_input":"2021-07-06T16:22:29.385597Z","iopub.status.idle":"2021-07-06T16:22:29.598519Z","shell.execute_reply.started":"2021-07-06T16:22:29.385558Z","shell.execute_reply":"2021-07-06T16:22:29.597472Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"85.57"},"metadata":{}}]},{"cell_type":"code","source":"# Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngaussian = gnb.fit(X_train, y_train)\nprediction_naive = gaussian.predict(X_test)\n\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nacc_gaussian","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:22:31.016001Z","iopub.execute_input":"2021-07-06T16:22:31.016409Z","iopub.status.idle":"2021-07-06T16:22:31.033715Z","shell.execute_reply.started":"2021-07-06T16:22:31.016323Z","shell.execute_reply":"2021-07-06T16:22:31.032537Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"77.68"},"metadata":{}}]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nclf = CatBoostClassifier(\n    iterations=10,\n#     verbose=5,\n)\n\ncatboost = clf.fit(X_train, y_train,\n    # cat_features=cat_features,\n    eval_set=(X_test, y_test),\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:24:15.965630Z","iopub.execute_input":"2021-07-06T16:24:15.966039Z","iopub.status.idle":"2021-07-06T16:24:16.261581Z","shell.execute_reply.started":"2021-07-06T16:24:15.966006Z","shell.execute_reply":"2021-07-06T16:24:16.260510Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Learning rate set to 0.206726\n0:\tlearn: 0.6288767\ttest: 0.6266781\tbest: 0.6266781 (0)\ttotal: 51ms\tremaining: 459ms\n1:\tlearn: 0.5801920\ttest: 0.5814590\tbest: 0.5814590 (1)\ttotal: 51.3ms\tremaining: 205ms\n2:\tlearn: 0.5408101\ttest: 0.5415290\tbest: 0.5415290 (2)\ttotal: 51.6ms\tremaining: 120ms\n3:\tlearn: 0.5093224\ttest: 0.5076102\tbest: 0.5076102 (3)\ttotal: 51.8ms\tremaining: 77.7ms\n4:\tlearn: 0.4914277\ttest: 0.4880850\tbest: 0.4880850 (4)\ttotal: 52.1ms\tremaining: 52.1ms\n5:\tlearn: 0.4742430\ttest: 0.4719607\tbest: 0.4719607 (5)\ttotal: 52.4ms\tremaining: 34.9ms\n6:\tlearn: 0.4615335\ttest: 0.4589765\tbest: 0.4589765 (6)\ttotal: 52.6ms\tremaining: 22.6ms\n7:\tlearn: 0.4490427\ttest: 0.4493682\tbest: 0.4493682 (7)\ttotal: 52.9ms\tremaining: 13.2ms\n8:\tlearn: 0.4403939\ttest: 0.4431770\tbest: 0.4431770 (8)\ttotal: 53.5ms\tremaining: 5.94ms\n9:\tlearn: 0.4316692\ttest: 0.4372236\tbest: 0.4372236 (9)\ttotal: 54.1ms\tremaining: 0us\n\nbestTest = 0.4372236135\nbestIteration = 9\n\n","output_type":"stream"}]},{"cell_type":"code","source":"acc_catboost = round(catboost.score(X_train, y_train) * 100, 2)\nacc_catboost","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:24:51.822048Z","iopub.execute_input":"2021-07-06T16:24:51.822409Z","iopub.status.idle":"2021-07-06T16:24:51.829770Z","shell.execute_reply.started":"2021-07-06T16:24:51.822376Z","shell.execute_reply":"2021-07-06T16:24:51.828729Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"84.4"},"metadata":{}}]},{"cell_type":"markdown","source":"It is observed that the best accuracy is obtained in the Random Forest Model, which we will use to make our submissions to the competition.","metadata":{}},{"cell_type":"markdown","source":"### Use the section below to submit on the test set","metadata":{}},{"cell_type":"code","source":"test_feature = test_set[['Age', 'Sex', 'Embarked', 'Title', 'Pclass', 'FamilySize']]\ntest_id = test_set['PassengerId']\ntest_feature.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:25:07.712715Z","iopub.execute_input":"2021-07-06T16:25:07.713050Z","iopub.status.idle":"2021-07-06T16:25:07.726719Z","shell.execute_reply.started":"2021-07-06T16:25:07.713020Z","shell.execute_reply":"2021-07-06T16:25:07.725454Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   Age  Sex  Embarked  Title  Pclass  FamilySize\n0    0    1         3      1       3           0\n1    0    2         1      2       3           1\n2    0    1         3      1       2           0\n3    0    1         1      1       3           0\n4    0    2         1      2       3           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Pclass</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_predictions = catboost.predict(test_feature)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:25:18.821842Z","iopub.execute_input":"2021-07-06T16:25:18.822189Z","iopub.status.idle":"2021-07-06T16:25:18.828734Z","shell.execute_reply.started":"2021-07-06T16:25:18.822157Z","shell.execute_reply":"2021-07-06T16:25:18.827274Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId' : test_id, 'Survived': test_predictions})\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:25:20.990143Z","iopub.execute_input":"2021-07-06T16:25:20.990543Z","iopub.status.idle":"2021-07-06T16:25:21.000638Z","shell.execute_reply.started":"2021-07-06T16:25:20.990503Z","shell.execute_reply":"2021-07-06T16:25:20.999689Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         1\n2          894         0\n3          895         0\n4          896         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T16:25:24.504902Z","iopub.execute_input":"2021-07-06T16:25:24.505630Z","iopub.status.idle":"2021-07-06T16:25:24.515142Z","shell.execute_reply.started":"2021-07-06T16:25:24.505571Z","shell.execute_reply":"2021-07-06T16:25:24.514161Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Use this data type conversion for the output feature, if the score comes as 0 in submission\n\n# model.predict(test_data).astype(int)","metadata":{},"execution_count":null,"outputs":[]}]}